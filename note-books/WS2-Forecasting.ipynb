{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# LAB1239 Part Three - Forecasting - Watson Studio - Notebook #2\n### Forecasting with SARIMAX\n### https://www.statsmodels.org/dev/examples/notebooks/generated/statespace_sarimax_stata.html\n##### Version:20200504"}, {"metadata": {}, "cell_type": "code", "source": "#Based on NOAA data / Python Book in\n#https://dataplatform.cloud.ibm.com/exchange/public/entry/view/a7432f0c29c5bda2fb42749f363bd9ff\n#", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# LABID\nLABID=\"00\" #Tow digits please <<<< ADJUST YOUR LABID <<<<<<\nmynoderedinstance=\"ws://thinklab\"+LABID+\".mybluemix.net/ws/myweather2/\"\nprint (\"LABID =\"+LABID)\nprint (mynoderedinstance)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Hello World! - Your LABID = \"+LABID)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Read Data File\nimport pandas as pd\nimport io\nimport requests\nimport calendar\nimport json\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport warnings\nwarnings.simplefilter('ignore')\n#IEDINBUR6_weather.csv.zip\nimport matplotlib.pyplot as plt\n\nurl=\"https://github.com/markusvankempen/ThinkLab1239/blob/master/data/DryAndWetDays20102018.csv.zip?raw=true\"\n\n#s=requests.get(url).content\n\nstation =\"myPWS\"\ndata_raw=pd.read_csv(url, compression='zip')\ndataM = data_raw.set_index(pd.DatetimeIndex(data_raw['date']))\n\ndataM['day'] = pd.to_datetime(dataM['date'])\ndataM.drop(['date'], axis=1, inplace=True)\ndataM=dataM.drop(columns=\"humidity\")\ndataM.head()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Excerise consistency data check -do we have data elements for everything...any outliers\n#print(dataM[\"2010\":\"2010\"][\"month_name\"])\nplt.figure(figsize=(16,8))\ndataM[\"2010\":\"2010\"][\"Wet\"].plot()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "import matplotlib.pyplot as plt\nimport seaborn as sns\n# Monthly plot of rainy days\nplt.figure(figsize=(12,8))\nsns.set_style(\"whitegrid\")\nsns.set_context(\"notebook\", font_scale=2)\nsns.barplot(x=\"month_name\", y=\"Dry\",  data=dataM[\"2016-01\":\"2016-12\"])\n\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of Dry Days\")\nplt.title(\"2016 {}\".format(station))\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Forecasting via SARIMAX\n#### Quick look at trends"}, {"metadata": {}, "cell_type": "code", "source": "import statsmodels.api as sm\n# Let's decompose the time series to visualize trend, season and noise separately \ndef decomposeNplot(data):\n  decomposition = sm.tsa.seasonal_decompose(data)\n\n  plt.figure(figsize=(20,12))\n\n  ax1 = plt.subplot(411)\n  decomposition.observed.plot(ax=ax1)\n  ax1.set_ylabel('Observed')\n\n  ax2 = plt.subplot(412)\n  decomposition.trend.plot(ax=ax2)\n  ax2.set_ylabel('Trend')\n\n  ax3 = plt.subplot(413)\n  decomposition.seasonal.plot(ax=ax3)\n  ax3.set_ylabel('Seasonal')\n\n  ax4 = plt.subplot(414)\n  decomposition.resid.plot(ax=ax4)\n  ax4.set_ylabel('Residuals')\n\n  return decomposition\n#decomposeNplot(train['T (degC)'])\ndecomposeNplot(dataM['Wet'])\n#decomposeNplot(dataWeekly['rainday'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Let's check for stationarity (Augmented Dickey Fuller test)\n#\u201cStationary\u201d usually refers to time series data. A timeseries is stationary if it has no drift/trend. \n#Equivalently, it's mean stays roughly constant. It's important because most statistical methods get weird \n#(and go wrong) when timeseries aren't stationary.\n#https://stats.stackexchange.com/questions/55805/how-do-you-interpret-results-from-unit-root-tests\n# P-value has to be smaller than 0.05 to be stationarity    \nfrom statsmodels.tsa.stattools import adfuller\n#results = adfuller(dataD)\n#print(results)\ndef adf_test(timeseries):\n    #Perform Dickey-Fuller test:\n    print ('Results of Dickey-Fuller Test:')\n    dftest = adfuller(timeseries, autolag='AIC')\n    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n    for key,value in dftest[4].items():\n       dfoutput['Critical Value (%s)'%key] = value\n    print (dfoutput)\n\n#apply adf test on the series\nadf_test(dataM['Wet'])\n#adf_test(dataWeekly['rainday'])", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Create SARIMAX Model"}, {"metadata": {}, "cell_type": "code", "source": "## Resampling the data to mothly and averaging out the temperature & we will predict the monthly average temperature\ntrain = dataM[:'2016']\ntest =  dataM['2016':]\nalldata=dataM[:'2018-03']['Dry']\n#alldata=dataM[:'2017-07']['Dry']\nftraindata = train['2016']['Dry']\nftestdata = test['Dry']\n\n#dataWeekly['rainday']\n#train = dataWeekly['2015':'2016']\n#test =  dataWeekly['2016':]\n#alldata=dataM['dataWeekly']\n#alldata=dataWeekly['2015':'2018-04']['rainday']\n#ftraindata = train['rainday']\n#ftestdata = test['rainday']\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\n#endog.index = endog.datetime\n#\n#endog = endog.drop(['T (degC)'])\n\n#exog.index = exog.dates\n#exog = exog.drop(['dates'], axis = 1)\n#Weekly \n#model = SARIMAX(alldata,order=(2,0,2),seasonal_order=(1,1,0,52),trend='ct', freq='W')#,endog = dataW  ,exog=dataW,\n#Monthly\nmodel = SARIMAX(alldata,order=(1, 0, 2),seasonal_order=(1, 1, 0, 12),trend='n',  freq='M',enforce_stationarity=True)\n#model = SARIMAX(dataM['Dry'],order=(2,0,2),trend='n',freq='M',enforce_stationarity=True)\n#(2, 0, 2)xh(1, 1, 0, 52)\nresults = model.fit()\n\nprint(np.mean(np.abs(results.resid)))\n\nresults.summary()\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#STEPS = Month eg 2 years\nforecast = results.get_forecast(steps=30)#len(ftestdata)) \nforecast.predicted_mean.head(10).round()\n#results(1).plot_diagnostics(figsize=(10,10))\n#results.summary()\n#forecast.conf_int().round()\n#forecast.conf_int().iloc[:,0].round()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "### Visualize our forecasted data\n#\n# Excerise try to use different data ranges \n#\ntrain = dataM[:'2015']\ntest =  dataM['2015':'2016']\nalldata=dataM['2016':]['Dry']\nftraindata = dataM['2015':]['Dry']\nftestdata = test['Dry']\n\n#dataWeekly['rainday']\n#train = dataWeekly['2016':'2016']\n#test =  dataWeekly['2016':]\n#alldata=dataWeekly['2016-07':].rainday\n#alldata=dataWeekly[:'2017-07']['rainday']\n#ftraindata = train['rainday']\n#ftestdata = test['rainday']\n\nbounds = forecast.conf_int()\nlower_limit = bounds.iloc[:,0]\nupper_limit = bounds.iloc[:,1]\nplt.figure(figsize=(16,10))\n\nplt.plot(ftraindata.index, ftraindata, label='train')\nplt.plot(alldata.index,alldata,label='actual')\n\nplt.plot(forecast.predicted_mean.index, forecast.predicted_mean.round(), color='r', label='forecast')\n\nplt.fill_between(lower_limit.index,lower_limit,upper_limit, color='pink')\n\nplt.xlabel('Date')\nplt.ylabel('Days of Rain')\nplt.legend()\nplt.show()\n#predictedmean.head().round()\nforecast.predicted_mean.head().round()", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Merging forecast to our dataset"}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "#\n# Note: we will have 2 datasets ...DataM - history dataset\n# ...DataF - Forecast dataset\n#\n#\ndataF = pd.DataFrame(forecast.predicted_mean.round())\ndataF.columns  = ['Dry']\ndataF['Wet']   = dataF['Dry'] \n#dataF['Wet']  = dataF['days']-dataF['fDry'] \ndataF['date']  = dataF.index\ndataF['date']  = pd.to_datetime(dataF['date'])#\ndataF['year']  = pd.DatetimeIndex(dataF['date']).year\ndataF['month'] = pd.DatetimeIndex(dataF['date']).month\ndataF['days']  = pd.DatetimeIndex(dataF['date']).day\ndataF['Wet']   = dataF['days']-dataF['Dry'] \n#dataF['Dry'] = dataF['fDry'] \n\ndataF[\"month_name\"] = dataF.month.apply(lambda x: calendar.month_abbr[x])\n#dataF.drop(colmun=\"Dry\")\n#Query Testing\nyy=\"2020\"\nmm=\"Jun\"\ndry=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][0]\nwet=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][1]\ngetInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}  \nprint(getInfo)\nprint(dataF['2020':'2020'].loc[dataF['month_name']  == \"Jun\"].values[0][6])\n#dataF['2020':'2020'].loc[dataF['month_name']  == \"Jan\"]\ndataF['2020':]\n#sel= dataF[\"2020-01\":\"2020-03\"]\n#sel.reset_index().to_json(orient='records')", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### Query Playgroud"}, {"metadata": {}, "cell_type": "code", "source": "# GetInfo\ndataY = dataF.resample('Y').mean(); # yearly averages\ndataY.year.count()\ngetInfo = '{\"cmd\":\"getInfo\",\"tablesize\":'+str(len(dataM))+',\"years\":'+str(dataY.year.count())+'}'; # yearly averages\n\nprint(getInfo)\n", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#getMay2020\ndatain = {'cmd' : 'getMay2020'}\ndry=dataF[\"2020\":].loc[dataF['month_name'] == 'Apr'].values[0][0] #fDry\nwet=dataF[\"2020\":].loc[dataF['month_name'] == 'Apr'].values[0][1]\nyy= dataF[\"2020\":].loc[dataF['month_name'] == 'Apr'].values[0][3]\nmm= dataF[\"2020\":].loc[dataF['month_name'] == 'Apr'].values[0][6]\n#temp=dataF[\"2020\":].loc[dataF['month_name'] == 'Apr'].values[0][4]\nmvk = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\nmvk[\"cmd\"]=datain['cmd']\nmvk", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#getForecastMonth\nyy='2020'\nmm='Jun'\ndry=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][0]\nwet=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][1]\ngetInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\n    \nprint(getInfo)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#getForecastRange\ndatain={\"cmd\":\"getForecastRange\",\"start\":\"2019-01\",\"end\":\"2019-03\"}\nstartym=datain['start'] \nendym=datain['end'] \nsel= dataF[startym:endym]\nmvk=sel.reset_index().to_json(orient='records')\ngetInfo={\"cmd\":\"getForecastRange\",\"info\":[]}\ninfo=json.loads(mvk)  \ngetInfo['info']=info\ndataF[startym:endym]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#if (datain['cmd'] == 'getRange'):  \n#\n# You could add or remove data elements !!!! \n#\ndatain={\"cmd\":\"getRange\",\"start\":\"2017-01\",\"end\":\"2017-04\"}\nstartym=datain['start'] \nendym=datain['end'] \nsel= dataM[startym:endym]\nmvk=sel.reset_index().to_json(orient='records')\ngetInfo={\"cmd\":\"cmd\",\"info\":[]}\ninfo=json.loads(mvk)  \n#info", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "datain={\"cmd\":\"getRange\",\"start\":\"2020-01\",\"end\":\"2020-04\"}\ndry=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][0]\nwet=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][1]\ngetInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\ngetInfo[\"cmd\"]=datain['cmd']    \n#getInfo", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Hello\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Connection to Node-RED <> python\n### Make sure to adjust the url below with your Node-RED instance"}, {"metadata": {}, "cell_type": "code", "source": "#Create commincaton with Node-RED instance \n#You need to instal the client 1st\n!pip install websocket-client\n\nimport websocket\nimport _thread\nimport time\nimport json\n\ndef on_open(ws):\n    print(\"on open\")\n    def run(*args):\n        for i in range(10000):\n            hbeat = '{\"cmd\":\"Python NB HeartBeat\"}'\n            print(\"send cmd\")\n            ws.send(hbeat)\n            time.sleep(1000)\n            \n    _thread.start_new_thread(run, ())\n\ndef on_error(ws, error):\n    print(error)\n\ndef on_close(ws):\n    print(\"closed\")\n#    start_websocket_listener()\n#    ws.send(\"Watson Studio Listen End\")\n\ndef on_message(ws, message):\n    print(message)\n    wet=-1\n    kw=0\n    dry=-1\n    kd=0\n    try:\n        datain = json.loads(message)\n        print(datain['cmd'])\n        # do the required stuff\n        # add more iformation maybe even the min/max temperature of the year\n        if (datain['cmd'] == 'hello'): # Add  more infos like numer of year/month\n            getInfo = '{\"cmd\":\"hello\",\"message\":\"hello to Node-RED.\"}'                     ### <<<<< Change the hello return message \n            print(getInfo)\n            ws.send(getInfo)\n            \n        if (datain['cmd'] == 'getInfo'): # Add  more infos like numer of year/month\n            getInfo = '{\"cmd\":\"getInfo\",\"tablesize\":'+str(len(dataM))+'}'\n            print(getInfo)\n            ws.send(getInfo)\n            \n        if (datain['cmd'] == 'getJan2017'):          \n            dry=dataM[\"2017\":\"2017\"].loc[dataM['month_name'] == 'Jan'].values[0][0]\n            wet=dataM[\"2017\":\"2017\"].loc[dataM['month_name'] == 'Jan'].values[0][1]\n            yy=dataM[\"2017\":\"2017\"].loc[dataM['month_name'] == 'Jan'].values[0][2]\n            mm=dataM[\"2017\":\"2017\"].loc[dataM['month_name'] == 'Jan'].values[0][3]\n            getInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))\n        #Get Rain for a month Month  in coming {\"cmd\":\"getRain\",\"month\":\"Feb\",\"year\":\"2018\"}\n        if (datain['cmd'] == 'getRain'):  \n            yy=datain['year'] \n            mm=datain['month'] \n            dry=dataM[yy:yy].loc[dataM['month_name'] == mm].values[0][0]\n            wet=dataM[yy:yy].loc[dataM['month_name'] == mm].values[0][1]\n            getInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))\n#  \n# Carefull with the Ranges - new function\n#\n        if (datain['cmd'] == 'getForecastMonth'):  \n            yy=datain['year'] \n            mm=datain['month'] \n            dry=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][0]\n            wet=dataF[yy:yy].loc[dataF['month_name'] == mm].values[0][1]\n            getInfo = {'Wet': wet,'Dry' : dry,\"Month\" : mm ,\"Year\":yy}\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))\n            \n        if (datain['cmd'] == 'getForecastRange'):  \n            startym=datain['start'] \n            endym=datain['end'] \n            sel= dataF[startym:endym]\n            mvk=sel.reset_index().to_json(orient='records')\n            getInfo={\"cmd\":\"getForecastRange\",\"info\":[]}\n            info=json.loads(mvk)  \n            getInfo['info']=info\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))\n            \n            \n        if (datain['cmd'] == 'getRange'):  \n            startym=datain['start'] \n            endym=datain['end'] \n            sel= dataM[startym:endym]\n            mvk=sel.reset_index().to_json(orient='records')\n            getInfo={\"cmd\":\"cmd\",\"info\":[]}\n            info=json.loads(mvk)  \n            getInfo['info']=info\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))\n            \n        if (datain['cmd'] == 'getTemp'):  \n            yy=datain['year'] \n            mm=datain['month'] \n            temp=dataM[yy:yy].loc[dataM['month_name'] == mm].values[0][4]\n            getInfo = {'Temp' :temp,\"Month\" : mm ,\"Year\":yy}\n            getInfo[\"cmd\"]=datain['cmd']    \n            print(getInfo)\n            ws.send(json.dumps(getInfo))            \n        if (datain['cmd'] == 'getAll'): \n            mysdata.to_json()\n       \n            \n    except Exception as e:\n        print(\"Error -  no json  / no  valid command?\")\n        print(e)\n####   ws://thinklab2020nr.mybluemix.net/ws/myweather/\"\n#### use your own isntance \ndef start_websocket_listener():\n    #websocket.enableTrace(True)\n    ws = websocket.WebSocketApp(mynoderedinstance, #<<<<<<< ADJUST\n                              on_message = on_message,\n                              on_error = on_error,\n                              on_close = on_close)\n    print(\"connecting\")\n   # ws.send(\"Watson Studio Listen open\")\n    ws.on_open = on_open\n    ws.run_forever()\n\nstart_websocket_listener() ", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Hello\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<a id=\"authors\"></a> \n### Authors"}, {"metadata": {}, "cell_type": "code", "source": "# Markus van Kempen - mvk@ca.ibm.com\n# Version:20200501", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "This notebook was created by the [Center for Open-Source Data & AI Technologies](http://codait.org).\n\nCopyright \u00a9 2019 IBM. This notebook and its source code are released under the terms of the MIT License."}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}